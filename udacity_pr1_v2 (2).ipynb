{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Imprts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import folium \n",
    "import missingno as msno\n",
    "import geopy.distance\n",
    "from sklearn.preprocessing import Imputer\n",
    "from collections import Counter\n",
    "\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# extra setting to show all columns in descriptive statistics\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_all = pd.read_csv(\"calendar_all.csv\", parse_dates=['date'])\n",
    "\n",
    "listings = pd.read_csv(\"listings.csv\")\n",
    "\n",
    "detailed_listings = pd.read_csv(\"detailed_listings.csv\", low_memory = False)\n",
    "\n",
    "neighbourhoods = pd.read_csv(\"neighbourhoods.csv\")\n",
    "\n",
    "reviews = pd.read_csv(\"reviews.csv\")\n",
    "\n",
    "detailed_reviews = pd.read_csv(\"detailed_reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get to know data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.Are where any duplicates? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicates_counts(df, name):\n",
    "    print(\"{} dataset has {} rows and {} columns and it contains {} duplicates\".format(name, df.shape[0], df.shape[1], df.duplicated().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_counts(listings, \"listings\")\n",
    "duplicates_counts(detailed_listings, \"detailed_listings\")\n",
    "duplicates_counts(neighbourhoods, \"neighbourhoods\")\n",
    "duplicates_counts(reviews, \"reviews\")\n",
    "duplicates_counts(detailed_reviews, \"detailed_reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculations show that there are duplicates in reviews dataset. But taking into account business logic, that the same day multiple users can evaluate their stay, it might be not true. I randomly selected one of duplicated values from review dataset and checked in dateiled_reviews dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[reviews.duplicated()].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_reviews[(detailed_reviews['listing_id'] == 61714) & (detailed_reviews['date'] == \"2017-05-29\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different users evaluate their stay. Unique of these values describes reviewer_id, reviewer_name and comment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Is there many missing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_missing_values(df):\n",
    "    msno.matrix(df)\n",
    "    print(df.columns[df.isnull().any()])\n",
    "    print(df.isnull().mean().sort_values(ascending = False).head(5))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identify_missing_values(listings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some missing values in last revew and reviews per month columns. This might be a result of new listings in Airbnb platform. Maybe listings are too new to get any feedback. Legend in the right indicate rows with the lowest and highest number of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identify_missing_values(detailed_listings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detailed_listings dataset had multiple columns with missing values. Columns with all null values: thumbnail_url, host_acceptance_rate, xl_picture_url          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.heatmap(detailed_listings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The missingno correlation heatmap measures nullity correlation. Where correlation = 1 means, that if one variable appears, the other one definetely appears. That might show us the structure of the data. Values marked as < 1, shows that there are some rows where not both records are presented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.dendrogram(detailed_listings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dendogram shows exact \"causality\" and relationship between columns. How each column is realted with other ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identify_missing_values(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As could be expected, reviews dataset has all values. As row is inserted after user submit a review. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identify_missing_values(detailed_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only few rows in detailed_reviews dataset have missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identify_missing_values(neighbourhoods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No issues in neighbourhoods dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identify_missing_values(calendar_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Dataset column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_all.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calender date value type changed to datetime, price and adjusted price should be changed to int value in order to user this value for calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_all['price'] = calendar_all.price.str.replace(\"[$, ]\", \"\").astype(\"float\")\n",
    "calendar_all['adjusted_price'] = calendar_all.adjusted_price.str.replace(\"[$, ]\", \"\").astype(\"float\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detailed_listings dataset has multiple columns with icorrect type. Some date values, prices stored as text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_listings.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listingsTypeDict = dict(detailed_listings.dtypes)\n",
    "listingsTypeDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price values convertion\n",
    "detailed_listings['price'] = detailed_listings.price.str.replace(\"[$, ]\", \"\").astype(\"float\")\n",
    "detailed_listings['cleaning_fee'] = detailed_listings.cleaning_fee.str.replace(\"[$, ]\", \"\").astype(\"float\")\n",
    "detailed_listings['weekly_price'] = detailed_listings.weekly_price.str.replace(\"[$, ]\", \"\").astype(\"float\")\n",
    "detailed_listings['monthly_price'] = detailed_listings.monthly_price.str.replace(\"[$, ]\", \"\").astype(\"float\")\n",
    "\n",
    "# response rate to value\n",
    "detailed_listings['host_response_rate'] = detailed_listings['host_response_rate'].str.replace(r'%', r'.0').astype('float') / 100.0\n",
    "\n",
    "\n",
    "# date values converted to date\n",
    "detailed_listings['host_since']= pd.to_datetime(detailed_listings['host_since']) \n",
    "detailed_listings['calendar_last_scraped']= pd.to_datetime(detailed_listings['calendar_last_scraped']) \n",
    "detailed_listings['last_review']= pd.to_datetime(detailed_listings['last_review']) \n",
    "detailed_listings['last_scraped']= pd.to_datetime(detailed_listings['last_scraped']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_reviews.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_reviews['date']= pd.to_datetime(detailed_reviews['date']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Fill missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to fill missing values of numeric columns, especially ones, which I am going to use in the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_all.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns with more than 30% of missing values I am going to drop. As this would be too much biased to fill values which are not known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = detailed_listings.isnull().mean().sort_values(ascending = False).where(lambda x : x> 0.3).dropna().to_frame().reset_index().rename(columns={\"index\": \"name\", 0: \"missing\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_value_cols = missing_values.name.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_listings = detailed_listings.drop(missing_value_cols, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If superhost value is nan, then mark as not superhost\n",
    "# detailed_listings.at[detailed_listings['host_is_superhost'].isnull(), 'review_scores_rating'] = 'f'\n",
    "detailed_listings['host_is_superhost'].fillna(\"f\", inplace=True)\n",
    "\n",
    "# If bathrooms value is nan, then replace with 0\n",
    "detailed_listings['bathrooms'].fillna(0, inplace=True)\n",
    "\n",
    "# If bedrooms value is nan, then median\n",
    "detailed_listings['bedrooms'].fillna((detailed_listings['bedrooms'].median()), inplace=True)\n",
    "\n",
    "# If beds value is nan, then mean, because it should be at least 1\n",
    "detailed_listings['beds'].fillna((detailed_listings['beds'].mean()), inplace=True)\n",
    "\n",
    "# If no cleaning fee provided, then assume to be 0\n",
    "detailed_listings['cleaning_fee'].fillna(0, inplace=True)\n",
    "\n",
    "# If no value for deposit, then assume to be 0\n",
    "detailed_listings['security_deposit'].fillna(0, inplace=True)\n",
    "\n",
    "# If no identification provided, then assume to be false - f\n",
    "detailed_listings['host_identity_verified'].fillna(\"f\", inplace=True)\n",
    "\n",
    "# If no photo provided, then assume to be false - f\n",
    "detailed_listings['host_has_profile_pic'].fillna(\"f\", inplace=True)\n",
    "\n",
    "# If the property was not booked or there were no evaluation, I am filling values with 0\n",
    "detailed_listings['review_scores_rating'].fillna(0, inplace=True)\n",
    "detailed_listings['review_scores_accuracy'].fillna(0, inplace=True)\n",
    "detailed_listings['review_scores_cleanliness'].fillna(0, inplace=True)\n",
    "detailed_listings['review_scores_checkin'].fillna(0, inplace=True)\n",
    "detailed_listings['review_scores_communication'].fillna(0, inplace=True)\n",
    "detailed_listings['review_scores_location'].fillna(0, inplace=True)\n",
    "detailed_listings['review_scores_value'].fillna(0, inplace=True)\n",
    "detailed_listings['reviews_per_month'].fillna(0, inplace=True)\n",
    "\n",
    "detailed_listings['host_response_rate'].fillna(0, inplace=True)\n",
    "detailed_listings['host_listings_count'].fillna(0, inplace=True)\n",
    "detailed_listings['host_total_listings_count'].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# text columns, if not provided, then \"\"\n",
    "detailed_listings['neighborhood_overview'].fillna(\"\", inplace=True)\n",
    "detailed_listings['house_rules'].fillna(\"\", inplace=True)\n",
    "detailed_listings['space'].fillna(\"\", inplace=True)\n",
    "detailed_listings['host_response_time'].fillna(\"\", inplace=True)\n",
    "detailed_listings['neighbourhood'].fillna(\"\", inplace=True)\n",
    "detailed_listings['summary'].fillna(\"\", inplace=True)\n",
    "detailed_listings['state'].fillna(\"Veneto\", inplace=True)\n",
    "detailed_listings['zipcode'].fillna(\"\", inplace=True)\n",
    "detailed_listings['description'].fillna(\"\", inplace=True)\n",
    "detailed_listings['host_location'].fillna(\"Venice, Veneto, Italy\", inplace=True)\n",
    "detailed_listings['city'].fillna(\"Venezia\", inplace=True)\n",
    "detailed_listings['host_thumbnail_url'].fillna(\"\", inplace=True)\n",
    "detailed_listings['host_name'].fillna(\"\", inplace=True)\n",
    "detailed_listings['smart_location'].fillna(\"Venice, Italy\", inplace=True)\n",
    "detailed_listings['host_picture_url'].fillna(\"\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5. Outliers detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some string type columns were converted to integers, look at decriptive statistics, to detect exceptional values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_all.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems unreasonale maximum price 1430 for 1 night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listings maximum price = 8459, while 75% is 150. That means there are outlers. Number of counts is quite difficult to test if 126 is the right maximum number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_listings.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maximum number of bathrooms value = 105, 75 percentile = 1.5, need outlier detection;\n",
    "\n",
    "price maximum value = 8459, 75 percentile = 150, need outlier detection;\n",
    "\n",
    "cleaning fee maximum value = 2222, 75 percentile = 60, need outlier detection;\n",
    "\n",
    "minimum nights maximum value = 107, while 75 percentile = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_outliers(df):\n",
    "#     num_train = df.select_dtypes(include=['number'])\n",
    "#     cat_train = df.select_dtypes(exclude=['number'])\n",
    "#     Q1 = num_train.quantile(0.25)\n",
    "#     Q3 = num_train.quantile(0.75)\n",
    "#     IQR = Q3 - Q1\n",
    "#     idx = ~((num_train < (Q1 - 1.5 * IQR)) | (num_train > (Q3 + 1.5 * \n",
    "#     IQR))).any(axis=1)\n",
    "#     train_cleaned = pd.concat([num_train.loc[idx], cat_train.loc[idx]], axis=1)\n",
    "#     return train_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['price', 'bathrooms', 'cleaning_fee']\n",
    "\n",
    "def remove_outliers(df, col_list):\n",
    "    num_train = df[col_list]\n",
    "    cat_cols = [col for col in df.columns if col not in col_list]    \n",
    "    cat_train = df[cat_cols]\n",
    "    Q1 = num_train.quantile(0.25)\n",
    "    Q3 = num_train.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    idx = ~((num_train < (Q1 - 1.5 * IQR)) | (num_train > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "    train_cleaned = pd.concat([num_train.loc[idx], cat_train.loc[idx]], axis = 1)\n",
    "    return train_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_listings = remove_outliers(detailed_listings, col_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6. Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because it is hardly to believe that all variables follow Normal distribution, I calculate Spearman correlation coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_correlation(df):\n",
    "    corr = df.corr(method=\"spearman\")\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    sns.heatmap(corr[(corr >= 0.8) | (corr <= -0.8)], \n",
    "            cmap='viridis', vmax=1.0, vmin=-1.0, linewidths=0.1,\n",
    "            annot=True, annot_kws={\"size\": 8}, square=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_correlation(detailed_listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_correlation(listings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Descriptive analysis/ add new columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Create new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 How far listing is from city center? Venice coordinates taken from: https://www.planetware.com/tourist-attractions-/venice-i-vn-v.htm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat, long = 45.434307, 12.339159"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings['central_lat'] = lat\n",
    "listings['central_long'] = long\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings['distance_km'] = listings.apply(\n",
    "    (lambda row: geopy.distance.geodesic(\n",
    "        (row['latitude'], row['longitude']),\n",
    "        (row['central_lat'], row['central_long'])\n",
    "    ).miles),\n",
    "    axis=1\n",
    ").round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.hist(column='distance_km')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_bins = [0, 0.5, 1, 1.5, 2, 3, 5, 10]\n",
    "listings['listings_km_bins'] = pd.cut(listings['distance_km'], bins = cut_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings['listings_km_bins'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2. How many days listing in platform?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculated the maximum and minimum day of last scraped. The first date is 2019-11-09, the last one 2019-12-06. This let me understand dates variability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_listings['last_scraped'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_listings['last_scraped'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then plotted and calculated numbers by date. where 8789 out of 8790 (99,99%) comes from 2019-11-09 and single record from 2019-12-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_listings.groupby(['last_scraped']).id.count().plot.bar(x='lab', y='val', rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_listings.groupby(['last_scraped']).id.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_listings[detailed_listings['last_scraped'] == \"2019-12-06\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_listings[detailed_listings['id'] == 31640251]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_listings[\"days_in_platform\"] = (detailed_listings['last_scraped'] - detailed_listings['host_since']).dt.days\n",
    "detailed_listings['days_in_platform'].fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3. Evaluate special amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Counter()\n",
    "detailed_listings['amenities'].str.strip('{}')\\\n",
    "               .str.replace('\"', '')\\\n",
    "               .str.lstrip('\\\"')\\\n",
    "               .str.rstrip('\\\"')\\\n",
    "               .str.split(',')\\\n",
    "               .apply(results.update)\n",
    "\n",
    "results.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_needs = pd.DataFrame(results.most_common(1000), columns=['amenity', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_needs.head(30).sort_values(by = ['count'], ascending = True).plot(kind='barh', x='amenity', y='count',  \n",
    "                                                      figsize = (10,7), legend = False, color = 'green',\n",
    "                                                      title = 'description')\n",
    "plt.xlabel('Count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract special amenities which are the most common in listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_listings['Heating'] = detailed_listings['amenities'].str.contains('Heating')\n",
    "detailed_listings['Essentials'] = detailed_listings['amenities'].str.contains('Essentials')\n",
    "detailed_listings['Wifi'] = detailed_listings['amenities'].str.contains('Wifi')\n",
    "detailed_listings['Hair_dryer'] = detailed_listings['amenities'].str.contains('Hair dryer')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2. Listings share by neighbourhood. The majority of listings is located in the island, as it contributes to total by 81.3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighboorhood = detailed_listings.groupby(\"neighbourhood_group_cleansed\").agg({'id' :'nunique'})\n",
    "neighboorhood.rename(columns = {\"id\": \"count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = detailed_listings[\"neighbourhood_group_cleansed\"].value_counts().plot(kind='bar',\n",
    "                                    figsize=(14,8),\n",
    "                                    title=\"Number by neighboorhood\")\n",
    "ax.set_xlabel(\"Neighboorhod\")\n",
    "ax.set_ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.Number of accomodation by room_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_listings['property_type'].value_counts().sort_values().plot(kind = 'barh', color = 'green')\n",
    "plt.title(\"Number of Accomodation by Property Type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  2.5. What is the mean, median of price by property type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x = \"property_type\", y = \"price\", data = detailed_listings)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation = 90)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6. Create Venice map with listing location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a map\n",
    "this_map = folium.Map(prefer_canvas=True)\n",
    "\n",
    "def plotDot(point):\n",
    "    '''input: series that contains a numeric named latitude and a numeric named longitude\n",
    "    this function creates a CircleMarker and adds it to your this_map'''\n",
    "    folium.CircleMarker(location=[point.latitude, point.longitude],\n",
    "                        radius=4,\n",
    "                        weight=0,#remove outline\n",
    "                        popup = point.name,\n",
    "                        fill_color='#blue').add_to(this_map)\n",
    "\n",
    "#use df.apply(,axis=1) to iterate through every row in your dataframe\n",
    "listings[['latitude', 'longitude', 'name']].apply(plotDot, axis = 1)\n",
    "\n",
    "\n",
    "#Set the zoom to the maximum possible\n",
    "this_map.fit_bounds(this_map.get_bounds())\n",
    "\n",
    "#Save the map to an HTML file\n",
    "this_map.save(('venice_map.html'))\n",
    "\n",
    "# this_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(filename='venice_map.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(filenaxme='venice_map.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7. When is the peak season?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_listings = calendar_all[calendar_all['available'] == 't']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add weekday of available listings\n",
    "available_listings['weekday'] = available_listings['date'].dt.weekday_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_listings.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_outliers\n",
    "col_list_dates = [\"price\"]\n",
    "remove_outliers(available_listings, col_list_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x = \"weekday\", y = \"price\", data = remove_outliers(available_listings, col_list_dates), order=[\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"])\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation = 90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unavailable_listings = calendar_all[calendar_all['available'] == 'f']\n",
    "unavailable_listings['weekday'] = unavailable_listings['date'].dt.weekday_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x = \"weekday\", y = \"price\", data = remove_outliers(unavailable_listings, col_list_dates), order=[\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"])\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation = 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distributions of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_detailed_listings = detailed_listings.select_dtypes(include=['int64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(19,10), dpi=50)\n",
    "int_detailed_listings.hist(ax=ax, layout=(7,7), alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_listings.drop(['id', 'host_id'], axis = 1).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.9 How clients review their stay?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to download stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(['english', 'italian', 'french'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add location values in italian and english\n",
    "stop_words.update([\"Venice\", \"Venezia\"])\n",
    "stop_words.update([\"us\", \"gave\", \"also\"])\n",
    "stop_words.update([\"de\", \"la\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_reviews[\"comments\"].fillna(\"no review\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(review for review in detailed_reviews.comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_mask = np.array(Image.open(\"eye_mask.png\"))\n",
    "eye_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_format(val):\n",
    "    if val == 0:\n",
    "        return 255\n",
    "    else:\n",
    "        return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_eyes_mask = np.ndarray((eye_mask.shape[0],eye_mask.shape[1]), np.int32)\n",
    "\n",
    "for i in range(len(eye_mask)):\n",
    "    transformed_eyes_mask[i] = list(map(transform_format, eye_mask[i]))\n",
    "transformed_eyes_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wc = WordCloud(max_font_size = 50, max_words = 150, background_color = \"white\", stopwords = stop_words, mask = eye_mask).generate(text)\n",
    "wc = WordCloud(max_font_size = 100, background_color=\"white\", max_words= 200, mask=transformed_eyes_mask, stopwords = stop_words, contour_width=3, contour_color='black').generate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc.to_file(\"mask.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[20,10])\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_listings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.10 What is the relationship between location and price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "sns.heatmap(detailed_listings.groupby(['neighbourhood', 'room_type']).price.median().unstack(), \n",
    "            cmap='Reds', annot=True, fmt=\".0f\")\n",
    "\n",
    "plt.xlabel('\\nRoom Type', fontsize=12)\n",
    "plt.ylabel('District\\n', fontsize=12)\n",
    "plt.title('\\nHeatmap: Median Prices by room type and district\\n\\n', fontsize=14, fontweight='bold');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.11 Which KPIS the most affect price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create temp df to avoid duplicate columns\n",
    "temp_listings = listings[['id', 'listings_km_bins']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.merge(detailed_listings, temp_listings,  how='left', left_on=['id'], right_on = ['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = ['price', 'bathrooms', 'cleaning_fee', \n",
    "        'host_is_superhost',\n",
    "       'host_total_listings_count',\n",
    "       'host_identity_verified',\n",
    "#        'property_type',\n",
    "                 'room_type',\n",
    "       'bedrooms', 'beds', \n",
    "       'minimum_nights', 'maximum_nights',\n",
    "       'number_of_reviews', 'review_scores_rating',\n",
    "       'days_in_platform', 'Heating', 'Essentials', 'Wifi', 'Hair_dryer', 'listings_km_bins']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_df = new_df[selected_cols]\n",
    "regression_df['listings_km_bins'] = regression_df.listings_km_bins.astype(str)\n",
    "\n",
    "regression_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(regression_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_cols = list(regression_df.select_dtypes(include='bool').columns)\n",
    "text_cols = list(regression_df.select_dtypes(include='object').columns)\n",
    "float_cols = list(regression_df.select_dtypes(include='float').columns)\n",
    "cols_ = bool_cols + text_cols\n",
    "regression_df[float_cols] = regression_df[float_cols].astype(int)\n",
    "\n",
    "regression = pd.get_dummies(regression_df, columns = cols_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = regression.drop(\"price\", axis = 1)\n",
    "y = regression.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()  \n",
    "regressor.fit(X_train, y_train) #training the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_df = pd.DataFrame(regressor.coef_, X.columns, columns=['Coefficient'])  \n",
    "coeff_df.sort_values(by=\"Coefficient\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
